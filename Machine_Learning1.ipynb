{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a1434-12b3-40b9-9dba-d289e0e0ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas numpy geopandas statsmodels scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed91e70d-1ec3-4789-b24b-8821cad07138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6c1eb7-098f-4452-9087-d207f484b960",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "GeoDataFrame does not support multiple columns using the geometry column name 'geometry'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m wpeed_shapefile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZonalStatisticWSpeed.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m wdir_shapefile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZonalStatisticWDir.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m fire_data \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(fire_shapefile)\n\u001b[0;32m     11\u001b[0m temp_data \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(temp_shapefile)\n\u001b[0;32m     12\u001b[0m rain_data \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(rain_shapefile)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:297\u001b[0m, in \u001b[0;36m_read_file\u001b[1;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_fiona(\n\u001b[0;32m    298\u001b[0m         path_or_bytes, from_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    299\u001b[0m     )\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\geopandas\\io\\file.py:395\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[1;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m    392\u001b[0m         [record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m f_filt], columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    393\u001b[0m     )\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 395\u001b[0m     df \u001b[38;5;241m=\u001b[39m GeoDataFrame\u001b[38;5;241m.\u001b[39mfrom_features(\n\u001b[0;32m    396\u001b[0m         f_filt, crs\u001b[38;5;241m=\u001b[39mcrs, columns\u001b[38;5;241m=\u001b[39mcolumns \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m datetime_fields:\n\u001b[0;32m    399\u001b[0m     as_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py:649\u001b[0m, in \u001b[0;36mGeoDataFrame.from_features\u001b[1;34m(cls, features, crs, columns)\u001b[0m\n\u001b[0;32m    647\u001b[0m     row\u001b[38;5;241m.\u001b[39mupdate(properties)\n\u001b[0;32m    648\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m--> 649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(rows, columns\u001b[38;5;241m=\u001b[39mcolumns, crs\u001b[38;5;241m=\u001b[39mcrs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py:163\u001b[0m, in \u001b[0;36mGeoDataFrame.__init__\u001b[1;34m(self, data, geometry, crs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    155\u001b[0m     geometry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# self[\"geometry\"] is a gdf and constructor gets recursively recalled\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# by pandas internals trying to access this\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 163\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    164\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoDataFrame does not support multiple columns \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    165\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing the geometry column name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         )\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# only if we have actual geometry values -> call set_geometry\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: GeoDataFrame does not support multiple columns using the geometry column name 'geometry'."
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the shapefiles\n",
    "fire_shapefile = \"JoinedLayer.shp\"\n",
    "temp_shapefile = \"ZonalStatisticTEMP.shp\"\n",
    "rain_shapefile = \"ZonalStatisticRain.shp\"\n",
    "wpeed_shapefile = \"ZonalStatisticWSpeed.shp\"\n",
    "wdir_shapefile = \"ZonalStatisticWDir.shp\"\n",
    "\n",
    "fire_data = gpd.read_file(fire_shapefile)\n",
    "temp_data = gpd.read_file(temp_shapefile)\n",
    "rain_data = gpd.read_file(rain_shapefile)\n",
    "humidity_data = gpd.read_file(humidity_shapefile)\n",
    "wind_data = gpd.read_file(wind_shapefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40dc19d8-c2e6-478c-b459-f4186395f9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acq_time</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ANN</th>\n",
       "      <th>monthly_fi</th>\n",
       "      <th>LISA_clust</th>\n",
       "      <th>Wdirmean</th>\n",
       "      <th>Rainmean</th>\n",
       "      <th>Wspeedmean</th>\n",
       "      <th>Tempmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1137</td>\n",
       "      <td>2002</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>842</td>\n",
       "      <td>2003</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  acq_time  YEAR  ANN  monthly_fi  LISA_clust  Wdirmean  Rainmean  \\\n",
       "0      1         0     0    0           0           0       0.0       0.0   \n",
       "1      2         0     0    0           0           0       0.0       0.0   \n",
       "2      3         0     0    0           0           0       0.0       0.0   \n",
       "3      4      1137  2002   23           2           2       0.0       0.0   \n",
       "4      4       842  2003   36          10           1       0.0       0.0   \n",
       "...   ..       ...   ...  ...         ...         ...       ...       ...   \n",
       "1333  66         0     0    0           0           0       0.0       0.0   \n",
       "1334  67         0     0    0           0           0       0.0       0.0   \n",
       "1335  68         0     0    0           0           0       0.0       0.0   \n",
       "1336  69         0     0    0           0           0       0.0       0.0   \n",
       "1337  70         0     0    0           0           0       0.0       0.0   \n",
       "\n",
       "      Wspeedmean  Tempmean  \n",
       "0            0.0       0.0  \n",
       "1            0.0       0.0  \n",
       "2            0.0       0.0  \n",
       "3            0.0       0.0  \n",
       "4            0.0       0.0  \n",
       "...          ...       ...  \n",
       "1333         0.0       0.0  \n",
       "1334         0.0       0.0  \n",
       "1335         0.0       0.0  \n",
       "1336         0.0       0.0  \n",
       "1337         0.0       0.0  \n",
       "\n",
       "[1338 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the CSV files\n",
    "#fire_data = pd.read_csv(\"\")\n",
    "#temp_data = pd.read_csv(\"Tempmeanzonal.csv\")\n",
    "#rain_data = pd.read_csv(\"RainZonalMean.csv\")\n",
    "\n",
    "winddir_data = pd.read_csv(\"Wdirmeanzonal.csv\")\n",
    "#windspeed_data = pd.read_csv(\"Wpeedmeanzonal.csv\")\n",
    "\n",
    "# Assuming 'ID' is the common attribute\n",
    "#merged_data = temp_data.merge(rain_data, on='id') \\\n",
    "                       #.merge(winddir_data, on='id') \\\n",
    "                       #.merge(windspeed_data, on='id')\n",
    "\n",
    "\n",
    "#merged_data\n",
    "winddir_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b074c99-d05f-4004-bd86-9af98f7e4ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ANN   R-squared:                       0.320\n",
      "Model:                            OLS   Adj. R-squared:                  0.318\n",
      "Method:                 Least Squares   F-statistic:                     156.7\n",
      "Date:                Mon, 27 May 2024   Prob (F-statistic):          5.59e-110\n",
      "Time:                        15:06:37   Log-Likelihood:                -7414.1\n",
      "No. Observations:                1338   AIC:                         1.484e+04\n",
      "Df Residuals:                    1333   BIC:                         1.486e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         34.4000      7.770      4.428      0.000      19.158      49.642\n",
      "Wdirmean     -45.1872      8.716     -5.185      0.000     -62.285     -28.089\n",
      "Rainmean      35.1314      2.231     15.744      0.000      30.754      39.509\n",
      "Wspeedmean   184.1674     11.638     15.825      0.000     161.337     206.997\n",
      "Tempmean       0.2717      0.059      4.624      0.000       0.156       0.387\n",
      "==============================================================================\n",
      "Omnibus:                       21.198   Durbin-Watson:                   0.368\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.866\n",
      "Skew:                           0.304   Prob(JB):                     1.79e-05\n",
      "Kurtosis:                       2.853   Cond. No.                     1.96e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.96e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Select dependent variable (e.g., number of fires)\n",
    "y = winddir_data['ANN']\n",
    "\n",
    "# Select independent variables (e.g., weather factors)\n",
    "X = winddir_data[['Wdirmean','Rainmean','Wspeedmean','Tempmean']]\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a3eddc-355b-485c-8108-1bfbaa26b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ANN   R-squared:                       0.320\n",
      "Model:                            OLS   Adj. R-squared:                  0.318\n",
      "Method:                 Least Squares   F-statistic:                     156.7\n",
      "Date:                Mon, 27 May 2024   Prob (F-statistic):          5.59e-110\n",
      "Time:                        15:07:46   Log-Likelihood:                -7414.1\n",
      "No. Observations:                1338   AIC:                         1.484e+04\n",
      "Df Residuals:                    1333   BIC:                         1.486e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         34.4000      7.770      4.428      0.000      19.158      49.642\n",
      "Wdirmean     -45.1872      8.716     -5.185      0.000     -62.285     -28.089\n",
      "Rainmean      35.1314      2.231     15.744      0.000      30.754      39.509\n",
      "Wspeedmean   184.1674     11.638     15.825      0.000     161.337     206.997\n",
      "Tempmean       0.2717      0.059      4.624      0.000       0.156       0.387\n",
      "==============================================================================\n",
      "Omnibus:                       21.198   Durbin-Watson:                   0.368\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.866\n",
      "Skew:                           0.304   Prob(JB):                     1.79e-05\n",
      "Kurtosis:                       2.853   Cond. No.                     1.96e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.96e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Predicted ANN value: 220.19818408619216\n",
      "Probability of fire occurrence: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming winddir_data is already loaded\n",
    "\n",
    "# Select dependent variable (e.g., number of fires)\n",
    "y = winddir_data['ANN']\n",
    "\n",
    "# Select independent variables (e.g., weather factors)\n",
    "X = winddir_data[['Wdirmean', 'Rainmean', 'Wspeedmean', 'Tempmean']]\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())\n",
    "\n",
    "# Function to predict ANN value and probability of fire occurrence\n",
    "def predict_fire_occurrence(Wdirmean, Rainmean, Wspeedmean, Tempmean):\n",
    "    # Create a DataFrame for the input values\n",
    "    input_data = pd.DataFrame({\n",
    "        'const': [1],  # Adding constant for intercept\n",
    "        'Wdirmean': [Wdirmean],\n",
    "        'Rainmean': [Rainmean],\n",
    "        'Wspeedmean': [Wspeedmean],\n",
    "        'Tempmean': [Tempmean]\n",
    "    })\n",
    "\n",
    "    # Predict the ANN value\n",
    "    predicted_ann = model.predict(input_data).iloc[0]\n",
    "\n",
    "    # Assuming a probability calculation based on the predicted ANN value\n",
    "    # For simplicity, we assume that if predicted_ann > 0, the probability is 1 (fire occurs)\n",
    "    # and if predicted_ann <= 0, the probability is 0 (no fire). This can be adjusted as needed.\n",
    "    probability_of_fire = 1 if predicted_ann > 0 else 0\n",
    "\n",
    "    return predicted_ann, probability_of_fire\n",
    "\n",
    "# Example usage\n",
    "Wdirmean = 1.0\n",
    "Rainmean = 10.0\n",
    "Wspeedmean = -1.0\n",
    "Tempmean = 235.0\n",
    "\n",
    "predicted_ann, probability_of_fire = predict_fire_occurrence(Wdirmean, Rainmean, Wspeedmean, Tempmean)\n",
    "\n",
    "print(f\"Predicted ANN value: {predicted_ann}\")\n",
    "print(f\"Probability of fire occurrence: {probability_of_fire}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64e5249-99d5-4565-834f-350a63ced1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ANN   R-squared:                       0.320\n",
      "Model:                            OLS   Adj. R-squared:                  0.318\n",
      "Method:                 Least Squares   F-statistic:                     156.7\n",
      "Date:                Mon, 27 May 2024   Prob (F-statistic):          5.59e-110\n",
      "Time:                        15:11:00   Log-Likelihood:                -7414.1\n",
      "No. Observations:                1338   AIC:                         1.484e+04\n",
      "Df Residuals:                    1333   BIC:                         1.486e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         34.4000      7.770      4.428      0.000      19.158      49.642\n",
      "Wdirmean     -45.1872      8.716     -5.185      0.000     -62.285     -28.089\n",
      "Rainmean      35.1314      2.231     15.744      0.000      30.754      39.509\n",
      "Wspeedmean   184.1674     11.638     15.825      0.000     161.337     206.997\n",
      "Tempmean       0.2717      0.059      4.624      0.000       0.156       0.387\n",
      "==============================================================================\n",
      "Omnibus:                       21.198   Durbin-Watson:                   0.368\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.866\n",
      "Skew:                           0.304   Prob(JB):                     1.79e-05\n",
      "Kurtosis:                       2.853   Cond. No.                     1.96e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.96e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Predicted ANN value: 24.351028337783077\n",
      "Probability of fire occurrence: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming winddir_data is already loaded\n",
    "\n",
    "# Select dependent variable (e.g., number of fires)\n",
    "y = winddir_data['ANN']\n",
    "\n",
    "# Select independent variables (e.g., weather factors)\n",
    "X = winddir_data[['Wdirmean', 'Rainmean', 'Wspeedmean', 'Tempmean']]\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())\n",
    "\n",
    "# Logistic function to convert ANN value to probability\n",
    "def logistic_function(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Function to predict ANN value and probability of fire occurrence\n",
    "def predict_fire_occurrence(Wdirmean, Rainmean, Wspeedmean, Tempmean):\n",
    "    # Create a DataFrame for the input values\n",
    "    input_data = pd.DataFrame({\n",
    "        'const': [1],  # Adding constant for intercept\n",
    "        'Wdirmean': [Wdirmean],\n",
    "        'Rainmean': [Rainmean],\n",
    "        'Wspeedmean': [Wspeedmean],\n",
    "        'Tempmean': [Tempmean]\n",
    "    })\n",
    "\n",
    "    # Predict the ANN value\n",
    "    predicted_ann = model.predict(input_data).iloc[0]\n",
    "\n",
    "    # Calculate the probability of fire occurrence using the logistic function\n",
    "    probability_of_fire = logistic_function(predicted_ann) * 100\n",
    "\n",
    "    return predicted_ann, probability_of_fire\n",
    "\n",
    "# Example usage\n",
    "Wdirmean = 1.0\n",
    "Rainmean = 4.0\n",
    "Wspeedmean = -1.0\n",
    "Tempmean = 290.0\n",
    "\n",
    "predicted_ann, probability_of_fire = predict_fire_occurrence(Wdirmean, Rainmean, Wspeedmean, Tempmean)\n",
    "\n",
    "print(f\"Predicted ANN value: {predicted_ann}\")\n",
    "print(f\"Probability of fire occurrence: {probability_of_fire:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a15cd5-8045-4855-842c-ef85baec043b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a68e6e6-1228-461d-87e5-f97d9a5d0d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269b3c7-d659-453b-8695-152a5ad114db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da88859-071c-4690-899a-c0f2b0c7ffdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954db270-d643-4802-aabc-2357efbf4ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db92a7-3d2e-44d3-8d4c-07b10487d2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c3dec-9147-442c-a65e-9a8f460daddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a1421-6252-4bee-a068-7fec71d48451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8907c-1ed6-4119-be70-69d074677d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2adcdc-4d46-430b-9a49-c8ffbf4d88a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df1982-b509-49ca-8dd8-749f33242748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb77d869-c548-4c29-9933-69838c24701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor - MSE: 2960.6097090204644, R2: 0.4431054718588304\n",
      "XGBoost Regressor - MSE: 2940.9208681292203, R2: 0.44680896837995865\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the data\n",
    "#data = pd.read_csv('path_to_your_data.csv')\n",
    "\n",
    "# Define your predictors and target variable\n",
    "#X = data[['predictor1', 'predictor2', 'predictor3', 'predictor4']]  # Adjust as necessary\n",
    "#y = data['target_variable']  # Adjust as necessary\n",
    "\n",
    "# Select dependent variable (e.g., number of fires)\n",
    "y = winddir_data['ANN']\n",
    "\n",
    "# Select independent variables (e.g., weather factors)\n",
    "X = winddir_data[['Wdirmean','Rainmean','Wspeedmean','Tempmean']]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gbr.fit(X_train, y_train)\n",
    "y_pred_gbr = gbr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_gbr = mean_squared_error(y_test, y_pred_gbr)\n",
    "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
    "\n",
    "print(f\"Gradient Boosting Regressor - MSE: {mse_gbr}, R2: {r2_gbr}\")\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgbr = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "xgbr.fit(X_train, y_train)\n",
    "y_pred_xgbr = xgbr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_xgbr = mean_squared_error(y_test, y_pred_xgbr)\n",
    "r2_xgbr = r2_score(y_test, y_pred_xgbr)\n",
    "\n",
    "print(f\"XGBoost Regressor - MSE: {mse_xgbr}, R2: {r2_xgbr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd422498-922c-4f6a-8a5d-612584a5f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting Regressor - MSE: 3072.0333019269688, R2: 0.42214654944281516\n",
      "Best XGBoost Regressor - MSE: 2940.9208681292203, R2: 0.44680896837995865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Gradient Boosting Regressor Hyperparameter Tuning\n",
    "param_grid_gbr = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_gbr = GridSearchCV(estimator=gbr, param_grid=param_grid_gbr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_gbr.fit(X_train, y_train)\n",
    "\n",
    "best_gbr = grid_gbr.best_estimator_\n",
    "y_pred_gbr_best = best_gbr.predict(X_test)\n",
    "mse_gbr_best = mean_squared_error(y_test, y_pred_gbr_best)\n",
    "r2_gbr_best = r2_score(y_test, y_pred_gbr_best)\n",
    "\n",
    "print(f\"Best Gradient Boosting Regressor - MSE: {mse_gbr_best}, R2: {r2_gbr_best}\")\n",
    "\n",
    "# XGBoost Regressor Hyperparameter Tuning\n",
    "param_grid_xgbr = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_xgbr = GridSearchCV(estimator=xgbr, param_grid=param_grid_xgbr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_xgbr.fit(X_train, y_train)\n",
    "\n",
    "best_xgbr = grid_xgbr.best_estimator_\n",
    "y_pred_xgbr_best = best_xgbr.predict(X_test)\n",
    "mse_xgbr_best = mean_squared_error(y_test, y_pred_xgbr_best)\n",
    "r2_xgbr_best = r2_score(y_test, y_pred_xgbr_best)\n",
    "\n",
    "print(f\"Best XGBoost Regressor - MSE: {mse_xgbr_best}, R2: {r2_xgbr_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0b808a-08f0-4efa-827f-24470ae0c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting Regressor - MSE: 2961.910546728411, R2: 0.4428607825979164\n",
      "Best XGBoost Regressor - MSE: 2957.6309209498254, R2: 0.4436657857603814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Expanded hyperparameter tuning for Gradient Boosting Regressor\n",
    "param_dist_gbr = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "random_search_gbr = RandomizedSearchCV(estimator=gbr, param_distributions=param_dist_gbr, n_iter=100, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search_gbr.fit(X_train, y_train)\n",
    "\n",
    "best_gbr = random_search_gbr.best_estimator_\n",
    "y_pred_gbr_best = best_gbr.predict(X_test)\n",
    "mse_gbr_best = mean_squared_error(y_test, y_pred_gbr_best)\n",
    "r2_gbr_best = r2_score(y_test, y_pred_gbr_best)\n",
    "\n",
    "print(f\"Best Gradient Boosting Regressor - MSE: {mse_gbr_best}, R2: {r2_gbr_best}\")\n",
    "\n",
    "# Expanded hyperparameter tuning for XGBoost Regressor\n",
    "param_dist_xgbr = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "random_search_xgbr = RandomizedSearchCV(estimator=xgbr, param_distributions=param_dist_xgbr, n_iter=100, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "random_search_xgbr.fit(X_train, y_train)\n",
    "\n",
    "best_xgbr = random_search_xgbr.best_estimator_\n",
    "y_pred_xgbr_best = best_xgbr.predict(X_test)\n",
    "mse_xgbr_best = mean_squared_error(y_test, y_pred_xgbr_best)\n",
    "r2_xgbr_best = r2_score(y_test, y_pred_xgbr_best)\n",
    "\n",
    "print(f\"Best XGBoost Regressor - MSE: {mse_xgbr_best}, R2: {r2_xgbr_best}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a4be3a-1520-41b8-a87f-8179ad8511f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation R² scores for Gradient Boosting Regressor: [0.48918768 0.41624537 0.37582286 0.35097284 0.32482355]\n",
      "Mean R²: 0.39141045914197703, Std R²: 0.05742673300997125\n",
      "Cross-Validation R² scores for XGBoost Regressor: [0.48943546 0.41411109 0.3773477  0.37150537 0.32568113]\n",
      "Mean R²: 0.3956161514698426, Std R²: 0.05468107132720782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Feature Engineering - Adding polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# K-Fold Cross-Validation for Gradient Boosting Regressor\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores_gbr = cross_val_score(gbr, X_poly, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f\"Cross-Validation R² scores for Gradient Boosting Regressor: {cross_val_scores_gbr}\")\n",
    "print(f\"Mean R²: {cross_val_scores_gbr.mean()}, Std R²: {cross_val_scores_gbr.std()}\")\n",
    "\n",
    "# K-Fold Cross-Validation for XGBoost Regressor\n",
    "cross_val_scores_xgbr = cross_val_score(xgbr, X_poly, y, cv=kf, scoring='r2')\n",
    "\n",
    "print(f\"Cross-Validation R² scores for XGBoost Regressor: {cross_val_scores_xgbr}\")\n",
    "print(f\"Mean R²: {cross_val_scores_xgbr.mean()}, Std R²: {cross_val_scores_xgbr.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d65da-535a-4f33-84b9-9b62618a78aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c005bc4-c637-456a-beb9-7eb0b274fb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd3e82-a2ed-41f3-b83c-0e2d5479dd5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385dfee4-28ab-40e8-a487-9d7a828bcea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf457cc-5f63-4497-b82b-1e71cab2eba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b652a-d5ca-4cbe-82af-d77ca95e6366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c7751-821b-4168-ab0d-2b277d1517f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f044a76-2498-41c9-a170-5e54fedf8b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15efc9-517b-4803-a7f0-2597a64ff6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
